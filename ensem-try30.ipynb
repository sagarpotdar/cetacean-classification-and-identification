{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freqs = pd.read_csv('/kaggle/input/happy-whale-and-dolphin/train.csv')\nprint(freqs.head())\nfreqs = freqs.groupby(by='individual_id').count()['species']\nfreqs = freqs.reset_index()\nfreqs.columns = ['individual_id','count']\nfreq = {}\nfor i in range(len(freqs)):\n    freq[freqs.loc[i,'individual_id']]=freqs.loc[i,'count']\ntest = pd.read_csv('/kaggle/input/whale-blend/test.csv', index_col='image')\nids = np.load(\"/kaggle/input/whale-blend/ids_without_backfin.npy\", allow_pickle = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test[['species']]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"species = pd.read_csv('/kaggle/input/happy-whale-and-dolphin/train.csv')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub1 = pd.read_csv('/kaggle/input/whale-blend/0-768.csv', index_col='image')\nsub0 = pd.read_csv('/kaggle/input/whale-blend/f6-10.csv', index_col='image')\nsub0a = pd.read_csv('/kaggle/input/whale-blend/andrij2.csv', index_col='image')\nsub1a =  pd.read_csv('/kaggle/input/whale-blend/1-768.csv', index_col='image')\nsub1b =  pd.read_csv('/kaggle/input/whale-blend/f2-768.csv', index_col='image')\n# sub1c =  pd.read_csv('/kaggle/input/whale-blend/6-768.csv', index_col='image')\nsub1c =  pd.read_csv('/kaggle/input/whale-blend/cv8245.csv', index_col='image')\nsub1d =  pd.read_csv('/kaggle/input/whale-blend/f3-768.csv', index_col='image')\nsub2 = pd.read_csv('/kaggle/input/whale-blend/5-768.csv', index_col='image')\nsub3 = pd.read_csv('/kaggle/input/whale-blend/f7a-768.csv', index_col='image')\nsub4 = pd.read_csv('/kaggle/input/whale-blend/f9-768-AUG.csv', index_col='image')\nsub5 = pd.read_csv('/kaggle/input/whale-blend/andrij.csv', index_col='image')\nsub6 = pd.read_csv('/kaggle/input/whale-blend/2-640.csv', index_col='image')\nsub7 = pd.read_csv('/kaggle/input/whale-blend/3-640.csv', index_col='image')\nsub8 = pd.read_csv('/kaggle/input/whale-blend/4-640.csv', index_col='image')\nsub9 = pd.read_csv('/kaggle/input/whale-blend/5-640.csv', index_col='image')\nsub10 = pd.read_csv('/kaggle/input/whale-blend/6-640-100.csv', index_col='image')\nsub11 = pd.read_csv('/kaggle/input/whale-blend/7-640.csv', index_col='image')\nsub12 = pd.read_csv('/kaggle/input/whale-blend/1-480.csv', index_col='image')\nsub13 = pd.read_csv('/kaggle/input/whale-blend/3-480-200.csv', index_col='image')\nsub14 = pd.read_csv('/kaggle/input/whale-blend/5-480.csv', index_col='image')\nsub15 = pd.read_csv('/kaggle/input/whale-blend/6-480.csv', index_col='image')\nsub16 = pd.read_csv('/kaggle/input/whale-blend/9-480.csv', index_col='image')\nsub17 = pd.read_csv('/kaggle/input/whale-blend/f4-1024.csv', index_col='image')\nsub18 = pd.read_csv('/kaggle/input/whale-blend/f8_803_65_786_1.csv.csv', index_col='image')\nsub19 = pd.read_csv('/kaggle/input/whale-blend/fold0.csv', index_col='image')\nsub20 = pd.read_csv('/kaggle/input/whale-blend/fold1.csv', index_col='image')\nsub21 = pd.read_csv('/kaggle/input/whale-blend/fold2.csv', index_col='image')\nsub22 = pd.read_csv('/kaggle/input/whale-blend/fold3.csv', index_col='image')\nsub23 = pd.read_csv('/kaggle/input/whale-blend/fold4.csv', index_col='image')\nsub24 = pd.read_csv('/kaggle/input/whale-blend/full.csv', index_col='image')\nsub25 = pd.read_csv('/kaggle/input/whale-blend/full480.csv', index_col='image')\nsub26 = pd.read_csv('/kaggle/input/whale-blend/full320.csv', index_col='image')\nsub27 = pd.read_csv('/kaggle/input/whale-blend/conv320.csv', index_col='image')\nsub28 = pd.read_csv('/kaggle/input/whale-blend/subback1_1.csv', index_col='image')\nsub29 = pd.read_csv('/kaggle/input/whale-blend/subback2_1.csv', index_col='image')\nsub30 = pd.read_csv('/kaggle/input/whale-blend/subback3.csv', index_col='image')\nsub31 = pd.read_csv('/kaggle/input/whale-blend/subback4_1.csv', index_col='image')\nsub32 = pd.read_csv('/kaggle/input/whale-blend/subback5_1.csv', index_col='image')\nsub33 = pd.read_csv('/kaggle/input/whale-blend/andrij_emb_blend.csv', index_col='image')\nsub34 = pd.read_csv('/kaggle/input/whale-blend/belug.csv', index_col='image')\nsub35 = pd.read_csv('/kaggle/input/whale-blend/fullbody.csv', index_col='image')\nsub36 = pd.read_csv('/kaggle/input/whale-blend/fb2.csv', index_col='image')\nsub37 = pd.read_csv('/kaggle/input/whale-blend/fullfb.csv', index_col='image')\nsub38 = pd.read_csv('/kaggle/input/happywhale-tpu-baseline-to-0-804-elasticface/submission.csv', index_col='image')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subs = [sub38,sub34, sub35,sub36,sub37,sub1,sub0,sub0a, sub1b,sub1c,sub4,sub5,sub6,sub10,sub17,sub18,sub19,sub20,sub21,sub22,sub23,sub24,sub25,sub27,sub28,sub29,sub30,sub31,sub32,sub33]\nfor i,sub in enumerate(subs):\n    test['prediction'+chr(i+0x41)] = sub['predictions']\ntest=test.reset_index()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(subs)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len([9,1,1.5,1,1,1,1.1,1,1,1,1.1,0.99,0.99,0.99,1,1,0.99,0.99,0.99,0.99,0.99,3,1,0.8,1.4,1.4,1.1,1.4,1.4,1.4])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()\n# sub1.fillna('new_individual new_individual new_individual new_individual new_individual',inplace=True)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def blender(weights, coefs):\n    res = {}\n    temp = []\n    blend = ''\n    ratios = []\n    for k, (weight,coef) in enumerate(zip(weights[2:],coefs)):\n        if weights[1] in ids and k>23:\n            pass\n        else:\n            for i in range(5):\n\n                if weight[i]!='new_individual':\n                    res[weight[i]]=res.get(weight[i],0)+blend_weights2(i)*coef-coef*freq.get(weight[i],0)/30\n\n\n                else:\n                    if i == 0:\n                        res[weight[i]]=res.get(weight[i],0)+(blend_weights2(i)-4.9)*coef\n                    elif i ==1:\n                        res[weight[i]]=res.get(weight[i],0)+(blend_weights2(i)-4.9)*coef\n                    else:\n                        res[weight[i]]=res.get(weight[i],0)+(blend_weights2(i)-2.5)*coef\n\n\n\n            \n    sorted_res = sorted(res.items(),reverse=True, key = lambda kv: kv[1])\n    for item in sorted_res:\n        temp.append(item[0])\n        ratios.append(item[1])\n#     temp = temp[1]\n    if ratios[0]-ratios[1]<5 and temp[0]=='new_individual':\n        temp[0],temp[1]=temp[1],temp[0]\n    blend = ' '.join(temp)\n    return blend\n# def blend_ratio(weights, coefs):\n#     res = {}\n#     temp = []\n#     for weight,coef in zip(weights,coefs):     \n#         for i in range(5):\n#             if weight[i]!='new_individual':\n#                 res[weight[i]]=res.get(weight[i],0)+blend_weights2(i)*coef\n#             else:\n#                 res[weight[i]]=res.get(weight[i],0)+(blend_weights2(i)-4)*coef\n#     sorted_res = sorted(res.items(),reverse=True, key = lambda kv: kv[1])\n#     for item in sorted_res:\n#         temp.append(item[1])\n#     return temp[1]/temp[0]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def blend_weights(num):\n    mapper = {0:10,1:4,2:8,3:6,4:3}\n    return mapper[num]\ndef blend_weights2(num):\n    mapper = {0:10,1:6.5,2:3.3,3:2.9,4:2.7,5:2.6,6:2.5,7:2.2,8:1.9,9:1.5}\n    return mapper[num]\ndef check_beluga(ind):\n    return species.loc[species.individual_id==ind, 'species'].min()=='beluga'\n    \n# def blend_weights_trans(num):\n#     mapper = {0:2,1:10,2:4,3:3,4:2}\n#     return mapper[num]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['predictions'] = test.apply(lambda row: blender([row[1].split(),row[0],row[2].split(),row[3].split(),row[4].split(),row[5].split(),row[6].split(),row[7].split(),row[8].split(),row[9].split(),row[10].split(),row[11].split(),row[12].split(),row[13].split(),row[14].split(),row[15].split(),row[16].split(),row[17].split(),row[18].split(),row[19].split(),row[20].split(),row[21].split(),row[22].split(),row[23].split(),row[24].split(),row[25].split(),row[26].split(),row[27].split(),row[28].split(),row[29].split(),row[30].split(),row[31].split()], [10,6,1.25,1,6,1,1.5,1,1,1,1,0.99,0.99,0.99,1,1,0.99,0.99,0.99,0.99,0.99,4,1,0.8,1.4,1.4,1.4,1.4,1.4,1.4]), axis=1)\n# sub1['ratio'] = sub1.apply(lambda row: blend_ratio([row[1].split(),row[2].split(),row[3].split(),row[4].split(),row[5].split(),row[6].split(),row[7].split(),row[8].split(),row[9].split(),row[10].split()], [0.9,0.9,0.9,1,0.75,0.9,1,0.75,0.75,0.9]), axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[['image','predictions']].to_csv('submission.csv',index=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[test['predictions'].str[:3]=='new'].count()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}